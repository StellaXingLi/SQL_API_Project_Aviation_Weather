{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# url = \"https://meteostat.p.rapidapi.com/point/hourly\"\n",
    "\n",
    "# querystring = {\"lat\":\"41.97694\",\"lon\":\"-87.908149\",\"start\":\"2019-01-15\",\"end\":\"2019-01-25\",\"alt\":\"113\",\"tz\":\"America/Toronto\"}\n",
    "\n",
    "# headers = {\n",
    "# \t\"X-RapidAPI-Key\": \"51ab1b611dmshe9b71ca60f61eb3p163ecbjsn00b9e87566c4\",\n",
    "# \t\"X-RapidAPI-Host\": \"meteostat.p.rapidapi.com\"\n",
    "# }\n",
    "\n",
    "# response = requests.get(url, headers=headers, params=querystring)\n",
    "\n",
    "# print(json.dumps(response.json(), indent=3))\n",
    "\n",
    "#use the python requestes cod from rapidapi to test the query about weather in chicago hourly from 2019-01-15 to 2019-01-25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply json decoder and save in weather_chicago\n",
    "weather_chicago = response.json()\n",
    "#print(weather_chicago)\n",
    "#creat jason object\n",
    "json_object = json.loads(response.content)\n",
    "print(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just to confirm the type\n",
    "# print(type(json_object['data']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test with json_normalize with the 'data' list\n",
    "# weather_chicago_norm = pd.json_normalize(json_object['data'])\n",
    "# weather_chicago_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creat values abotu lat, lon and airport_code for later merge with flights and airports table\n",
    "# this dataframe is about the hourly data of 10 days for 6 airports \n",
    "# but the 'snow' column is none, which means we also need daily data \n",
    "lat =[\"41.97694\",\"35.21375\",\"32.897233\",\"32.897233\",\"39.872084\",\"33.434278\"]\n",
    "lon =[\"-87.908149\",\"-80.949055\",\"-97.037694\",\"-80.290115\",\"-80.290115\",\"-112.011582\"]\n",
    "airport_code = [\"ORD\",\"CLT\",\"DFW\",\"MIA\",\"PHL\",\"PHX\"]\n",
    "\n",
    "weather_hourly_df=pd.DataFrame([])\n",
    "for i in range(6):\n",
    "    lat[i]\n",
    "    lon[i]#this for loop will go through lat and lon as a pair\n",
    "    url = \"https://meteostat.p.rapidapi.com/point/hourly\"\n",
    "\n",
    "    querystring = {\"lat\":lat[i],\"lon\":lon[i],\"start\":\"2019-01-15\",\"end\":\"2019-01-25\",\"tz\":\"America/Toronto\"}\n",
    "\n",
    "    headers = {\n",
    "\t    \"X-RapidAPI-Key\": \"51ab1b611dmshe9b71ca60f61eb3p163ecbjsn00b9e87566c4\",\n",
    "\t    \"X-RapidAPI-Host\": \"meteostat.p.rapidapi.com\"}\n",
    "\n",
    "    response = requests.get(url, headers=headers, params=querystring)\n",
    "    weather_dth = response.json()\n",
    "    weather_dth_df = pd.json_normalize(weather_dth,\n",
    "                                    sep='_',\n",
    "                                    record_path='data')\n",
    "    weather_dth_df['faa']=airport_code[i]#creat a column called faa for airport code \n",
    "    weather_hourly_df = pd.concat([weather_hourly_df,weather_dth_df])\n",
    "    #print(json.dumps(response.json(), indent=3))\n",
    "    time.sleep(1)\n",
    "\n",
    "#weather_hourly_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_hourly_df.head()\n",
    "#column to keep :temp, rhum as relative humidity, wdir as wind(from) direction,wspd as average wind speed,\n",
    "#prcp as hourly  precipitation total in mm,\n",
    "#and coco as weather condition code, faa for airports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename the columns for easy understanding\n",
    "weather_hourly_df.rename(columns = {'rhum':'relative_humidity',\n",
    "                                    'wdir':'wind_direction',\n",
    "                                    'wspd':'avg_wind_speed',\n",
    "                                    'prcp':'hourly_precipitation'},inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to drop irrelevant columns from the table\n",
    "weather_hourly_df.drop(['dwpt','snow','wpgt','tsun','pres'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_hourly_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the columns name and find the meaning\n",
    "weather_hourly_df['coco'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_hourly_df['coco'] = weather_hourly_df['coco'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creat a weather condition list to explain the number in coco column\n",
    "weather_condition_list = [\"None\",\n",
    "                          \"Clear\",\n",
    "                          \"Fair\",\n",
    "                          \"Cloudy\",\n",
    "                          \"Overcast\",\n",
    "                          \"Fog\",\n",
    "                          \"Freezing_Fog\",\n",
    "                          \"Light_Rain\",\n",
    "                          \"Rain\",\n",
    "                          \"Heavy Rain\",\n",
    "                          \"Freezing Rain\",\n",
    "                          \"Heavy Freezing Rain\",\n",
    "                          \"Sleet\",\n",
    "                          \"Heavy Sleet\",\n",
    "                          \"Light Snowfall\",\n",
    "                          \"Snowfall\",\n",
    "                          \"Heavy Snowfall\",\n",
    "                          \"Rain Shower\",\n",
    "                          \"Heavy Rain Shower\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the 'weather_condition'column to translate the coco number\n",
    "#need to use map() when there is object but this time it is just number\n",
    "weather_hourly_df['weather_condition'] = [weather_condition_list[i] for i in weather_hourly_df['coco'].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_hourly_df.drop(['coco'],axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_hourly_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_hourly_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat =[\"41.97694\",\"35.21375\",\"32.897233\",\"32.897233\",\"39.872084\",\"33.434278\"]\n",
    "lon =[\"-87.908149\",\"-80.949055\",\"-97.037694\",\"-80.290115\",\"-80.290115\",\"-112.011582\"]\n",
    "airport_code = [\"ORD\",\"CLT\",\"DFW\",\"MIA\",\"PHL\",\"PHX\"]\n",
    "\n",
    "weather_daily_df=pd.DataFrame([])\n",
    "for i in range(6):\n",
    "    lat[i]\n",
    "    lon[i]#this for loop will go through lat and lon as a pair\n",
    "    url = \"https://meteostat.p.rapidapi.com/point/daily\"\n",
    "\n",
    "    querystring = {\"lat\":lat[i],\"lon\":lon[i],\"start\":\"2019-01-15\",\"end\":\"2019-01-25\"}\n",
    "\n",
    "    headers = {\n",
    "\t    \"X-RapidAPI-Key\": \"51ab1b611dmshe9b71ca60f61eb3p163ecbjsn00b9e87566c4\",\n",
    "\t    \"X-RapidAPI-Host\": \"meteostat.p.rapidapi.com\"}\n",
    "\n",
    "    response = requests.get(url, headers=headers, params=querystring)\n",
    "    weather_dtd= response.json()\n",
    "    weather_dtd_df = pd.json_normalize(weather_dtd,\n",
    "                                    sep='_',\n",
    "                                    record_path='data')\n",
    "    weather_dtd_df['faa']=airport_code[i]#creat a column called faa for airport code \n",
    "    weather_daily_df = pd.concat([weather_daily_df,weather_dtd_df])\n",
    "    #print(json.dumps(response.json(), indent=3))\n",
    "    time.sleep(1)\n",
    "\n",
    "#weather_daily_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_daily_df.head()\n",
    "#columns to keep:snow as snow depth,prcp as daily  precipitation total in mm and faa as primary key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_daily_df_subset = weather_daily_df[['date','snow','prcp','faa']]\n",
    "#pd.set_option('display.max_rows', None) \n",
    "#display(weather_daily_df_subset)\n",
    "weather_daily_df_subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_daily_df_subset['snow'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2019-01-15'\n",
    "end_date = '2019-01-25'\n",
    "\n",
    "# Filter the data for the selected date range\n",
    "selected_date_range_data = weather_daily_df_subset[(weather_daily_df_subset['date'] >= start_date) & (weather_daily_df_subset['date'] <= end_date)]\n",
    "\n",
    "# Plot the snow depth for each airport over the selected date range\n",
    "plt.figure(figsize=(12, 8))\n",
    "for airport in selected_date_range_data['faa'].unique():\n",
    "    airport_data = selected_date_range_data[selected_date_range_data['faa'] == airport]\n",
    "    plt.plot(airport_data['date'], airport_data['snow'], label=airport, marker='o')\n",
    "\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Snow Depth (mm)')\n",
    "plt.title(f'Snow Depth at Airports ({start_date} to {end_date})')\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1, 1))  # Position legend outside the plot\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better readability\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weather_whole_df = weather_hourly_df.merge(weather_daily_df_subset,how='left',on='faa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sql_functions import get_engine\n",
    "from sql_functions import get_data\n",
    "from sql_functions import get_sql_config\n",
    "from sql_functions import get_dataframe\n",
    "import sqlalchemy\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = 'hh_analytics_23_4'\n",
    "\n",
    "\n",
    "sql_config = get_sql_config()\n",
    "engine = sqlalchemy.create_engine('postgresql://user:pass@host/database',\n",
    "                        connect_args=sql_config # use dictionary with config details\n",
    "                        ) \n",
    "\n",
    "table_name = 'weather_api_group3'\n",
    "\n",
    "# Write records stored in a dataframe to SQL database\n",
    "if engine!=None:\n",
    "    try:\n",
    "      weather_hourly_df.to_sql(name=table_name, # Name of SQL table\n",
    "                        con=engine, # Engine or connection\n",
    "                        if_exists='replace', # Drop the table before inserting new values \n",
    "                        schema=schema, # Use schmea that was defined earlier\n",
    "                        index=False, # Write DataFrame index as a column\n",
    "                        chunksize=5000, # Specify the number of rows in each batch to be written at a time\n",
    "                        method='multi') # Pass multiple values in a single INSERT clause\n",
    "      print(f\"The {table_name} table was imported successfully.\")\n",
    "    # Error handling\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "        engine = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query1 = f\"select time,temp,avg_wind_speed,faa,weather_condition from {schema}.weather_api_group3 where faa='ORD';\"\n",
    "chicago_df = get_dataframe(query1)\n",
    "chicago_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'time' column to a datetime object\n",
    "chicago_df['time'] = pd.to_datetime(chicago_df['time'])\n",
    "\n",
    "# Extract the date from the timestamp to create a 'date' column\n",
    "chicago_df['date'] = chicago_df['time'].dt.date\n",
    "\n",
    "# Filter the data for ORD (O'Hare International Airport)\n",
    "ord_data = chicago_df[chicago_df['faa'] == 'ORD']\n",
    "\n",
    "\n",
    "# Group by date and calculate the average temperature for each day\n",
    "daily_avg_temp = ord_data.groupby('date')['temp'].mean()\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 8))\n",
    "daily_avg_temp.plot(marker='o', linestyle='-', label='Average Temperature (°C)')\n",
    "\n",
    "# Adding weather condition information as annotations\n",
    "for date, condition in ord_data.groupby('date')['weather_condition'].last().items():\n",
    "    plt.annotate(condition, xy=(date, daily_avg_temp[date]), xytext=(5, 5),\n",
    "                 textcoords='offset points', arrowprops=dict(facecolor='black', arrowstyle='wedge,tail_width=0.7'))\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Daily Average Temperature and Weather Condition in ORD')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Temperature (°C)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query2 = f\"select time,temp,avg_wind_speed,faa,weather_condition from {schema}.weather_api_group3 where faa='PHL';\"\n",
    "philadelphia_df = get_dataframe(query2)\n",
    "philadelphia_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "philadelphia_df['time'] = pd.to_datetime(philadelphia_df['time'])\n",
    "philadelphia_df['date'] = philadelphia_df['time'].dt.date\n",
    "phl_data = philadelphia_df[philadelphia_df['faa'] == 'PHL']\n",
    "daily_avg_temp = philadelphia_df.groupby('date')['temp'].mean()\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "daily_avg_temp.plot(marker='o', linestyle='-', label='Average Temperature (°C)')\n",
    "\n",
    "for date, condition in philadelphia_df.groupby('date')['weather_condition'].last().items():\n",
    "    plt.annotate(condition, xy=(date, daily_avg_temp[date]), xytext=(5, 5),\n",
    "                 textcoords='offset points', arrowprops=dict(facecolor='black', arrowstyle='wedge,tail_width=0.7'))\n",
    "\n",
    "plt.title('Daily Average Temperature and Weather Condition in MIA')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Temperature (°C)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_flights = f'select * from {schema}.flights_by_paul;'\n",
    "flights_df = get_dataframe(query_flights)\n",
    "flights_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_df['hour_dep_time']=pd.to_datetime(flights_df['sched_dep_time_utc'],format = '%H:%M:%S').dt.hour\n",
    "flights_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_df['sched_hour_dep'] = flights_df['flight_date']+pd.to_timedelta(flights_df['hour_dep_time'],unit='hour')\n",
    "flights_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_weather = f'select * from {schema}.weather_api_group3;'\n",
    "weather_df = get_dataframe(query_weather)\n",
    "weather_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df['time_new']=pd.to_datetime(weather_df['time'])\n",
    "weather_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "merged_wf_df = flights_df.merge(weather_df,how='left',left_on=['sched_hour_dep','origin'],right_on=['time_new','faa'])\n",
    "merged_wf_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_wf_df_subset=merged_wf_df[['time_new','origin','faa','dep_delay','total_delay','temp','weather_condition','cancelled']]\n",
    "merged_wf_df_subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_wf_df_subset.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_wf_df_subset.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_wf_df_subset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_coco_dict = {'None':'0',\n",
    "                     'Clear': '1',\n",
    "                     'Fair':'2',\n",
    "                     'Cloudy':'3',\n",
    "                     'Overcast':'4',\n",
    "                     'Fog':'5',\n",
    "                     'Freezing_Fog':'6',\n",
    "                     'Light_Rain':'7',\n",
    "                     'Rain':'8',\n",
    "                     'Heavy Rain':'9',\n",
    "                     'Freezing Rain':'10',\n",
    "                     'Heavy Freezing Rain':'11',\n",
    "                     'Sleet':'12',\n",
    "                     'Heavy Sleet':'13',\n",
    "                     'Light Snowfall':'14',\n",
    "                     'Snowfall':'15',\n",
    "                     'Heavy Snowfall':'16',\n",
    "                     'Rain Shower':'17',\n",
    "                     'Heavy Rain Shower':'18'}\n",
    "\n",
    "\n",
    "\n",
    "merged_wf_df_subset['coco'] = merged_wf_df_subset['weather_condition'].map(weather_coco_dict)\n",
    "\n",
    "#df_all['aircraft_type'] = df_all['type_acft'].map(acft_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_wf_df_subset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city = 'ORD'\n",
    "merged_wf_df_ord = merged_wf_df_subset.loc[merged_wf_df_subset['faa'] == city]\n",
    "merged_wf_df_ord['temp'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_wf_df_subset['temp'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merged_wf_df_subset['dep_delay'] = pd.to_numeric(merged_wf_df_subset['dep_delay'], errors='coerce')\n",
    "merged_wf_df_subset['coco'] = pd.to_numeric(merged_wf_df_subset['coco'], errors='coerce')\n",
    "\n",
    "# Now, calculate the correlation coefficient\n",
    "correlation_matrix = merged_wf_df_subset[['coco', 'cancelled']].corr()\n",
    "correlation_coefficient = correlation_matrix.loc['coco', 'cancelled']\n",
    "\n",
    "print(f'Correlation Coefficient between weather_condition and cancelled: {correlation_coefficient}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_wf_df_2 = flights_df.merge(weather_df,how='left',left_on=['sched_hour_dep','dest'],right_on=['time_new','faa'])\n",
    "merged_wf_df_2.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_wf_df2_subset=merged_wf_df_2[['time_new','dest','faa','arr_delay','total_delay','temp','weather_condition']]\n",
    "merged_wf_df2_subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_wf_df2_subset.dropna(inplace=True)\n",
    "merged_wf_df2_subset.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_wf_df2_subset['coco'] = merged_wf_df2_subset['weather_condition'].map(weather_coco_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_wf_df2_subset['arr_delay'] = pd.to_numeric(merged_wf_df2_subset['arr_delay'], errors='coerce')\n",
    "merged_wf_df2_subset['coco'] = pd.to_numeric(merged_wf_df2_subset['coco'], errors='coerce')\n",
    "\n",
    "# Now, calculate the correlation coefficient\n",
    "correlation_matrix = merged_wf_df2_subset[['arr_delay', 'coco']].corr()\n",
    "correlation_coefficient = correlation_matrix.loc['arr_delay', 'coco']\n",
    "\n",
    "print(f'Correlation Coefficient between arr_delay and weather_condition: {correlation_coefficient}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_daily_df_subset['date_new']=pd.to_datetime(weather_daily_df_subset['date'])\n",
    "weather_daily_df_subset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flights_df.info()\n",
    "weather_daily_df_subset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_wf_df_3 = flights_df.merge(weather_daily_df_subset,how='left',left_on=['flight_date','origin'],right_on=['date_new','faa'])\n",
    "merged_wf_df_3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_wf_df_3_subset = merged_wf_df_3[['flight_date','origin','sched_hour_dep','dep_delay','cancelled','snow','faa','date_new']]\n",
    "merged_wf_df_3_subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_wf_df_3_subset.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_wf_df_3_subset.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_wf_df_3_subset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city = 'ORD'\n",
    "merged_wf_df3_ord = merged_wf_df_3_subset.loc[merged_wf_df_3_subset['faa'] == city]\n",
    "merged_wf_df3_ord\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_wf_df3_ord.drop_duplicates()\n",
    "merged_wf_df3_ord.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_wf_df3_ord['snow'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merged_wf_df_3_subset['dep_delay'] = pd.to_numeric(merged_wf_df_3_subset['dep_delay'], errors='coerce')\n",
    "\n",
    "# Now, calculate the correlation coefficient\n",
    "correlation_matrix = merged_wf_df3_ord[['cancelled', 'snow']].corr()\n",
    "correlation_coefficient = correlation_matrix.loc['cancelled', 'snow']\n",
    "\n",
    "print(f'Correlation Coefficient between dep_delay and snow_depth: {correlation_coefficient}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nf_sql",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
