{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ed21fd9",
   "metadata": {},
   "source": [
    "# How to download flights csv file from transtats website"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac59b93e",
   "metadata": {},
   "source": [
    "**In this notebook, we will**\n",
    "1. Download a csv file for each of your chosen year(s) and month(s)\n",
    "2. Prepare the data for further processing\n",
    "3. Push the prepared data to a table in the database\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b777e805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2 # needed to get database exception errors when uploading dataframe\n",
    "import requests # package for getting data from the web\n",
    "from zipfile import * # package for unzipping zip files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f576d796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the get_engine function from our sql_functions.\n",
    "from sql_functions import get_engine #adjust this as necessary to match your sql_functions.py connection methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc483e3e",
   "metadata": {},
   "source": [
    "# 1. Download csv file with flight data for your specific year/month"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3c3fe3",
   "metadata": {},
   "source": [
    "In the following, you are going to download a csv file containing flight data from [this website](https://transtats.bts.gov).    \n",
    "You can specify, which data you want to download. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09d000b",
   "metadata": {},
   "source": [
    "Choose a month/year that you want to explore further.\n",
    "With the following functions, you will download a csv file on public flight data from [this website](https://transtats.bts.gov) containing data of your chosen month/year.    \n",
    "The file will be stored in a data folder.\n",
    "Check out the url from which we download the data(https://transtats.bts.gov/PREZIP). Can we download data in this way from every source? What do you think?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a61deca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifies path for saving file\n",
    "path ='data/' \n",
    "# Create the data folder\n",
    "!mkdir {path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5dff7a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get specified csv file from the website https://transtats.bts.gov\n",
    "\n",
    "def download_data(year, month):\n",
    "    # Get the file from the website https://transtats.bts.gov\n",
    "    zip_file = f'On_Time_Reporting_Carrier_On_Time_Performance_1987_present_{year}_{month}.zip'\n",
    "    url = (f'https://transtats.bts.gov/PREZIP/{zip_file}')\n",
    "    # Download the database\n",
    "    r = requests.get(f'{url}', verify=False)\n",
    "    # Save database to local file storage\n",
    "    with open(path+zip_file, 'wb') as f:\n",
    "        f.write(r.content)\n",
    "        print(f'--> zip_file with name: {zip_file} downloaded succesfully.' )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1588f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to extract the csv files inside the zip files\n",
    "\n",
    "def extract_zip(year, month):\n",
    "    # Get the file from the website https://transtats.bts.gov\n",
    "    zip_file = f'On_Time_Reporting_Carrier_On_Time_Performance_1987_present_{year}_{month}.zip'\n",
    "    with ZipFile(path+zip_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(path)\n",
    "        csv_file =  zip_ref.namelist()[0]\n",
    "        print(f'--> zip_file was succesfully extracted to: {csv_file}.' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3c824f",
   "metadata": {},
   "source": [
    "Don't worry - the following download of the data you chose may take some time ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8738fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/nf_sql_3/lib/python3.9/site-packages/urllib3/connectionpool.py:1061: InsecureRequestWarning: Unverified HTTPS request is being made to host 'transtats.bts.gov'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> zip_file with name: On_Time_Reporting_Carrier_On_Time_Performance_1987_present_2019_1.zip downloaded succesfully.\n",
      "--> zip_file was succesfully extracted to: On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_2019_1.csv.\n"
     ]
    }
   ],
   "source": [
    "years_list = [2019] # list of years you want to look at (can of course also be a single year)\n",
    "months_list = [1] # list of months you want to look at (can of course also be a single month)\n",
    "\n",
    "# download flights data as zipfile(s)\n",
    "# we use a nested loop to specify the years and months to define the range of the data we would like to have \n",
    "for year in years_list:\n",
    "    for month in months_list:\n",
    "        download_data(year, month)\n",
    "        extract_zip(year, month)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5956edf",
   "metadata": {},
   "source": [
    "Now it is time to load the csv files into dataframes. You can create your own function equivalent to the functions above. But you need to decide whether...\n",
    "\n",
    "- Do you need one dataframe for every month?\n",
    "- Would you like to proceed with only one dataframe containing all the data you downloaded?\n",
    "- One dataframe for every year?\n",
    "\n",
    "There are certain things to consider before.\n",
    "- changing column names\n",
    "- dealing with missing data\n",
    "- changing datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b82b9ca2",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/flights_jan19.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m csv_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflights_jan19.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Read in your data\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mcsv_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlow_memory\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m display(df\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      7\u001b[0m display(df\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/nf_sql_3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/nf_sql_3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/nf_sql_3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/nf_sql_3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/nf_sql_3/lib/python3.9/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/flights_jan19.csv'"
     ]
    }
   ],
   "source": [
    "# define the name of the csv file you want to read in\n",
    "csv_file = 'flights_jan19.csv'\n",
    "\n",
    "# Read in your data\n",
    "df = pd.read_csv(path+csv_file, low_memory = False)\n",
    "display(df.shape)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fdf703",
   "metadata": {},
   "source": [
    "# 2. Prepare the csv file for further processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f4e575",
   "metadata": {},
   "source": [
    "In the next step, we clean and prepare our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441c52f5",
   "metadata": {},
   "source": [
    "a) Since the dataset consists of a lot of columns, we we define which ones to keep.  \n",
    "(Same as known from our SQL exercises on flights data.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c35afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns from downloaded file that are to be kept\n",
    "\n",
    "columns_to_keep = [\n",
    "                'FlightDate',\n",
    "                'DepTime',\n",
    "                'CRSDepTime',\n",
    "                'DepDelay',\n",
    "                'ArrTime',\n",
    "                'CRSArrTime',\n",
    "                'ArrDelay',\n",
    "                'Reporting_Airline',\n",
    "                'Tail_Number',\n",
    "                'Flight_Number_Reporting_Airline',\n",
    "                'Origin',\n",
    "                'Dest',\n",
    "                'AirTime',\n",
    "                'ActualElapsedTime',\n",
    "                'Distance',\n",
    "                'Cancelled',\n",
    "                'Diverted'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c182c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The columns in the database have different naming as in the source csv files. Lets get the names from the database\n",
    "\n",
    "schema = '______' # UPDATE 'TABLE_SCHEMA' based on schema used in class \n",
    "engine = get_engine() # assign engine to be able to query against the database\n",
    "\n",
    "table_name_sql = f'''SELECT COLUMN_NAME \n",
    "                    FROM INFORMATION_SCHEMA.COLUMNS \n",
    "                    WHERE TABLE_NAME = 'flights'\n",
    "                    AND TABLE_SCHEMA ='{schema}'\n",
    "                    ORDER BY ordinal_position'''\n",
    "c_names = engine.execute(table_name_sql).fetchall()\n",
    "c_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7369d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can clean up the results into a clean list\n",
    "new_column_names=[]\n",
    "for name in c_names:\n",
    "    new_column_names.append(name[0])\n",
    "new_column_names        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09331857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just in case the above fails here are the results\n",
    "'''new_column_names_alternate = ['flight_date', 'dep_time', 'sched_dep_time', 'dep_delay', 'arr_time', 'sched_arr_time', \n",
    "                'arr_delay', 'airline', 'tail_number', 'flight_number', 'origin', 'dest', 'air_time', 'actual_elapsed_time', 'distance', 'cancelled', 'diverted' ]'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d59e6ec",
   "metadata": {},
   "source": [
    "b) With the next function, we make our csv file ready to be uploaded to SQL.  \n",
    "We only keep to above specified columns and convert the datatypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c725271",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_airline_df(df):\n",
    "    '''\n",
    "    Transforms a df made from BTS csv file into a df that is ready to be uploaded to SQL\n",
    "    Set rows=0 for no filtering\n",
    "    '''\n",
    "\n",
    "    # Build dataframe including only the columns you want to keep\n",
    "    df_airline = df.loc[:,columns_to_keep]\n",
    "     \n",
    "    # Clean data types and NULLs\n",
    "    df_airline['FlightDate']= pd.to_datetime(df_airline['FlightDate'], yearfirst=True)\n",
    "    df_airline['CRSArrTime']= pd.to_numeric(df_airline['CRSArrTime'], downcast='integer', errors='coerce')\n",
    "    df_airline['Cancelled']= pd.to_numeric(df_airline['Cancelled'], downcast='integer')\n",
    "    df_airline['Diverted']= pd.to_numeric(df_airline['Diverted'], downcast='integer')\n",
    "    df_airline['ActualElapsedTime']= pd.to_numeric(df_airline['ActualElapsedTime'], downcast='integer', errors='coerce')\n",
    "    \n",
    "    # Rename columns\n",
    "    df_airline.columns = new_column_names\n",
    "    \n",
    "    return df_airline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7b4082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call function and check resulting dataframe\n",
    "df_clean = clean_airline_df(df)\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b742a452",
   "metadata": {},
   "source": [
    "If you decide to only look at specific airports, it is a good decision to filter for them in advance.  \n",
    "This function does the filtering. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42676a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the airports you are interested in and put them as a list in the function.\n",
    "def select_airport(df, airports):\n",
    "    ''' Helper function for filtering the airline dataframe for a subset of airports'''\n",
    "    df_out = df.loc[(df.origin.isin(airports)) | (df.dest.isin(airports))]\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339add17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute function, filtering for New York area airports\n",
    "airports=['JFK', 'LGA', 'EWR']\n",
    "if len(airports) > 0:\n",
    "    df_selected_airports = select_airport(df_clean, airports)\n",
    "else:\n",
    "    df_selected_airports = df_clean\n",
    "    \n",
    "df_selected_airports.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635eaad3",
   "metadata": {},
   "source": [
    "# 3. Push the prepared data to a table in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45a3970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify which table within your database you want to push your data to. Give your table an unambiguous name.\n",
    "# Example: flights_sp for Sina's flights table, flights_groupname or similar\n",
    "table_name = '______'\n",
    "# If the specified table doesn't exist yet, it will be created\n",
    "# With 'replace', your data will be replaced if the table already exists.\n",
    "# This may take some time ...\n",
    "\n",
    "# Write records stored in a dataframe to SQL database\n",
    "if engine!=None:\n",
    "    try:\n",
    "        df_selected_airports.to_sql(name=table_name, # Name of SQL table\n",
    "                        con=engine, # Engine or connection\n",
    "                        if_exists='replace', # Drop the table before inserting new values \n",
    "                        schema=schema, # Use schmea that was defined earlier\n",
    "                        index=False, # Write DataFrame index as a column\n",
    "                        chunksize=5000, # Specify the number of rows in each batch to be written at a time\n",
    "                        method='multi') # Pass multiple values in a single INSERT clause\n",
    "        print(f\"The {table_name} table was imported successfully.\")\n",
    "    # Error handling\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "        engine = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcdcb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just to be sure: Check if the number of rows match\n",
    "table_name_sql = f'''SELECT count(*) \n",
    "                    FROM {schema}.{table_name}\n",
    "                    '''\n",
    "engine.execute(table_name_sql).fetchall()[0][0] == df_selected_airports.shape[0]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6c96e12ea435425e5eacdf5151fc2e31f65462d718b52a4ac07f3a4743bbc86b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('sql-practice')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
